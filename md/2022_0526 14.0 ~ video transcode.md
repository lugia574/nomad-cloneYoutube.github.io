# 14 WEBASSEMBLY VIDEO TRANSCODE

## 14.0 Introduction

현재 녹화를 하고 webm 형식으로 다운로드 받을 수 있음

근데 다운 받은 영상은 갈이가 없음 존나 이상함

이걸 해결할꺼임

`FFmpeg` 를 가지고 비디오를 webm에서 mp4로 변환할꺼임

    FFmpeg

    1. 비디오에 관한 것을 핸들링(비디오 압축, 포맷 변환,
    오디오 제거 및 추출, 형식 변환, 비디오 스크린샷, 자막 추가 등등)
    할 수 있는 소프트웨어로, 컴퓨터에 설치할 수 있다.

    2. FF를 실행하려면 백엔드에서 실행해야만 한다. 그래서 서버 비용이 발생하게 된다 .


    https://www.ffmpeg.org/

근데 돈듬 우린 거지임

그래서 다른 방법으로 할꺼임

바로 `WebAssembly` 임

웹어셈블리는 우리가 프론트엔드에서 매우 빠른 코드를 실행할 수 있게 해줌

사용자의 브라우저에서 비디오를 변환하게 할꺼임

`WebAssembly` 를 이용해서 `FFmpeg`가 실행되게 할꺼임

```
npm install @ffmpeg/ffmpeg @ffmpeg/core
```

    FFmpeg
    오디오 및 비디오를 기록, 변환 및 스트리밍하는 완벽한 크로스
     플랫폼 솔루션입니다. FFmpeg는 인간과 기계가 만든 거의 모든 것을
      디코딩, 인코딩, 트랜스코딩, mux, demux, 스트리밍, 필터링 및
      재생할 수 있는 최고의 멀티미디어 프레임워크입니다.

    https://www.ffmpeg.org/

    FFmpeg WebAssembly
    WebAssembly에서 제공하는 브라우저 및 노드용 FFmpeg
    ffmpeg.wasm은 FFmpeg의 순수한 Webassembly/Javascript 포트입니다. 그것은 비디오 및 오디오 녹음, 변환, 스트리밍 등을
     브라우저 내부에서 할 수 있도록 합니다.
    FFmpeg WebAssembly를 사용하는 이유는 FFmpeg를 사용해서
    브라우저로 하여금 비디오 파일을 변환하기 위함이다.

    npm install @ffmpeg/ffmpeg @ffmpeg/core
    https://github.com/ffmpegwasm/ffmpeg.wasm
    https://www.npmjs.com/package/@ffmpeg/ffmpeg

    WebAssembly
    WebAssembly(Wasm)는 스택 기반 가상 머신을 위한 이진 명령
    형식입니다. Wasm은 프로그래밍 언어를 위한 이식 가능한 컴파일
     대상으로 설계되어 클라이언트 및 서버 응용 프로그램을 위해 웹에
      배포할 수 있습니다.

    웹 어셈블리는 자바스크립트의 무덤일까?
    https://www.youtube.com/watch?v=KjgDxBLv0bM

## 14.1 Transcode Video

우린 브라우저를 통해 녹화된 비디오 URL을 받고 있음

`createObjectURL` 을 사용해서 해당 URL 파일을 참조 할 수 있는거임

원하는건 사용자가 handleDownload를 누르면 영상을 불러서 변환하는거임

ffmpeg를 사용하는 방법은

`createFFmpeg`, `fetchFile` 두 함수를 import 하고

```js
import { createFFmpeg, fetchFile } from "@ffmpeg/ffmpeg";
//const { createFFmpeg, fetchFile } = require(`@ffmpeg/ffmpeg`);
```

그리고 FFmpeg instance 를 만들어주고

ffmpeg.load() 를 await 해줌

```js
const handleDownload = async () => {
  const ffmpeg = createFFmpeg({ log: true });
  await ffmpeg.load();
  //  아래 생략
};
```

await 한 이유는 사용자가 소프트웨어 사용할것이라

소프트웨어가 무거울수 있기 때문에 기다려줘야함

await 를 썼으니까 async 도 써주자

이제 할일은 ffmpeg에 파일을 만드는 거임

`ffmpeg.FS()` 를 하면 3가지 method가 있음

- writeFile

- readFile

- unlink

```js
ffmpeg.FS("writeFile", "recording.webm", await fetchFile(videoFile));
```

`writeFile` 은 ffmpeg의 세계에 파일을 생성해줘

한마디로 가상 검퓨터에 파일을 생성해준거임

거기에 파일명을 전송해줄껀데 ` recording.webm` 란 파일을 만들꺼임

다음에는 binaryData function 을 줘야함

그게 바로 `URL.createObjectURL(event.data)` 를 담아둔

`videoFile`

이걸 `fetchFile` 에 박는거임

이러면 ffmpeg의 세계에 파일을 만든거임

이제

```js
await ffmpeg.run();
```

에 원하는 명령어를 입력하는 거임

```
"-i", "recording.webm"
```

`recording.webm` 란 파일명을 가진 파일을 input 한다

가상 컴퓨터에 이미 존재하는 파일을 input으로 받는다는 소리임

output 으로 "output.mp4" 파일명을 써주면 됨

```
"-r", "60"
```

요건 초당 60프레임으로 인코딩 해줘라는 소리임

이러면

```js
await ffmpeg.run("-i", "recording.webm", "-r", "60", "output.mp4");
```

종합하면

```js
const handleDownload = async () => {
  const ffmpeg = createFFmpeg({ log: true });
  await ffmpeg.load();

  ffmpeg.FS("writeFile", "recording.webm", await fetchFile(videoFile));

  await ffmpeg.run("-i", "recording.webm", "-r", "60", "output.mp4");

  // ....생략....
};
```

근데 막상 하면 오류가 뜨는데

```

http://localhost:4000/node_modules/@ffmpeg/core/dist/ffmpeg-core.js 404 (Not Found) 또는
createFFmpegCore is not defined

(@ffmpeg/ffmpeg": "^0.10.0 이상으로 진행시)

```

`recorder.js`

```js
const ffmpeg = createFFmpeg({
  corePath: "https://unpkg.com/@ffmpeg/core@0.10.0/dist/ffmpeg-core.js",
  log: true,
});
await ffmpeg.load();

// ... 생략 ....
```

그럼 이제 이런 오류가 뜨는데

```
Uncaught (in promise) ReferenceError: SharedArrayBuffer is not defined

SharedArrayBuffer는 cross-origin isolated된 페이지에서만 사용할 수 있습니다. 따라서 ffmpeg.wasm을 사용하려면 Cross-Origin-Embedder-Policy: require-corp 및 Cross-Origin-Opener-Policy: same-origin를 header에 설정해 자체 서버를 호스팅해야 합니다.

```

라우터 앞에 이것을 추가

`server.js`

```js
app.use((req, res, next) => {
  res.header("Cross-Origin-Embedder-Policy", "require-corp");
  res.header("Cross-Origin-Opener-Policy", "same-origin");
  next();
});
```

이러면 또 깃헙 아바타가 오류 뜸 ㅋㅋㅋㅋ

그리고 crossorigingithub 아바타에 추가.

`header.pug`

```pug
img.header__avatar(src=loggedInUser.avatarUrl,crossorigin)
```

오류에 오류에 오류인것이었따~

## 14.2 Download Transcoded Video

다운을 받으면 여전히 webm 으로 받아지는데

output을 가지고 뭘 한게 없으니까

이제 변환된 비디오를 다운 받아보자

지금 브라우저 메모리에는 output.mp4라는 파일이 있음

해당 파일을 불러보자

```js
const mp4File = ffmpeg.FS("readFile", "output.mp4");
```

참고로 이 파일은 Unit8Array(array of 8-bit unsigned integers)타입이 될꺼임

Uint8Array 형식 배열은 8비트 부호 없는 정수 배열

한마디로 정수들의 조합이라는거임

영상은 존나 많은 숫재 배열들인데 이걸 Blob 형태로 변환할꺼임

파일 같은 객체로 만드는거임

Uint8Array를 사용하려면 먼저 ArrayBuffer를 해야함

```js
const mp4Blob = new Blob([mp4File.buffer], { type: "video/mp4" });
```

js 에게 이건 video/mp4 type 의 파일이라고 알려함

이 데이터를 우리가 접근할 수 있는 URL로 변환해주면 됨

그게 바로 `createObjectURL` 임

```js
const mp4URL = URL.createObjectURL(mp4Blob);

const a = document.createElement("a");
a.href = mp4URL;
a.download = "MyRecording.mp4";
document.body.appendChild(a);
a.click();
```

개같이 mp4 변환 성공 ㅋ

## 14.3 Thumbnail

이제 썸네일을 조져보자

스크린샷 찍는 명령어는 이거임

```js
await ffmpeg.run(
  "-i",
  "recording.webm",
  "-ss",
  "00:00:01",
  "-frames:v",
  "1",
  "thumbnail.jpg"
);
```

`"-ss", "00:00:01"`

는 01초로 이동한다는 소리고

`"-frames:v", "1"`

는 첫 프레임 스크린샷을 찍는다는 거임

`"thumbnail.jpg"`

thumbnail.jpg 이름으로 만들어 달라 이 소리

그럼 이제 파일을 읽어야지

```js
const thumbnail = ffmpeg.FS("readFile", "thumbnail.jpg");
const thumbBlob = new Blob([thumbnail.buffer], { type: "image/jpg" });
const thumURL = URL.createObjectURL(thumbBlob);
```

녹화 영상을 다운로드 기능을 구현 할때

파일을 다운로드 할 수 있는 링크를 추가하고 클릭할 수 있게 했음

섬네일도 똑같이 적용할꺼임

```js
const thumA = document.createElement("a");
thumA.href = thumURL;
thumA.download = "MyThumbnail.jpg";
document.body.appendChild(thumA);
thumA.click();
```

굳

야 근데 이럼 파일변환 기능도 내가 만들 수 있는거 아닌가

굳이 변환 프로그램같은거 안써도 되는거자나

파일 업로드 pug 받고 그거 req 로 받아가지고

그걸

```js
ffmpeg.FS("writeFile", "recording.해당 파일형식", await fetchFile(req 로 받은 파일));
```

이걸로 ffmpeg 에 넣고 만들고 변환하고 하면 되는거 아닌가??

가능은 할듯? 근데 파일 크기가 좀 커지면 내 브라우저 박살 나는거 아닌가?

근데 좀 꼴리는데? 나중에 내꺼 만들때 함 해보자

## 14.4 Recap

이 기능을 계속 사용하면 브라우저가 무거워 질 수 있음

그러니까 링크를 해제하면 좋음

```js
ffmpeg.FS("unlink", "recorder.webm");
ffmpeg.FS("unlink", "output.mp4");
ffmpeg.FS("unlink", "thumbnail.jpg");

URL.revokeObjectURL(mp4URL);
URL.revokeObjectURL(thumURL);
URL.revokeObjectURL(videoFile);
```

## 14.5 Thumbnail Upload part One

우선 코드 정리 좀 하고

썸네일을 위한 파일 input을 추가해주자

```js
import { createFFmpeg, fetchFile } from "@ffmpeg/ffmpeg";

const files = {
  input: "recording.webm",
  output: "output.mp4",
  thumb: "thumbnail.jpg",
};

const downloadFile = (fileUrl, fileName) => {
  const a = document.createElement("a");
  a.href = fileUrl;
  a.download = fileName;
  document.body.appendChild(a);
  a.click();
};

const { async } = require("regenerator-runtime");

const actionBtn = document.getElementById("actionBtn");
const video = document.getElementById("preview");

let stream;
let recorder;
let videoFile;

const handleDownload = async () => {
  actionBtn.removeEventListener("click", handleDownload);
  actionBtn.innerText = "Transcoding~";
  actionBtn.disabled = true;

  const ffmpeg = createFFmpeg({
    corePath: "https://unpkg.com/@ffmpeg/core@0.10.0/dist/ffmpeg-core.js",
    log: true,
  });
  await ffmpeg.load();

  ffmpeg.FS("writeFile", files.input, await fetchFile(videoFile));

  await ffmpeg.run("-i", files.input, "-r", "60", files.output);
  await ffmpeg.run(
    "-i",
    files.input,
    "-ss",
    "00:00:01",
    "-frames:v",
    "1",
    files.thumb
  );

  const mp4File = ffmpeg.FS("readFile", files.output);
  const thumbnail = ffmpeg.FS("readFile", files.thumb);

  const mp4Blob = new Blob([mp4File.buffer], { type: "video/mp4" });
  const thumbBlob = new Blob([thumbnail.buffer], { type: "image/jpg" });

  const mp4URL = URL.createObjectURL(mp4Blob);
  const thumbURL = URL.createObjectURL(thumbBlob);

  downloadFile(mp4URL, "MyRecording.mp4");
  downloadFile(thumbURL, "MyThumbnail.jpg");

  ffmpeg.FS("unlink", files.input);
  ffmpeg.FS("unlink", files.output);
  ffmpeg.FS("unlink", files.thumb);

  URL.revokeObjectURL(mp4URL);
  URL.revokeObjectURL(thumbURL);
  URL.revokeObjectURL(videoFile);

  actionBtn.disabled = false;
  actionBtn.innerText = "Record Again";
  actionBtn.addEventListener("click", handleStart);
};
```

여러번 쓰는 파일명은 변수 처리하고

녹화 버튼 기능을 더 보강함

이제 백엔드를 수정해보자

`Video`(스키마)에 thumbnailUrl 을 추가할꺼임

```js
const videoSchema = new mongoose.Schema({
  title: { type: String, required: true, trim: true, maxLength: 80 },
  fileUrl: { type: String, required: true },
  thumbUrl: { type: String, required: true },
  // .... 생략 ....
});
```

`upload.pug`

```pug
extends base.pug


block content
    div
        video#preview
        button#actionBtn Start Recording
    if errorMessage
        span=errorMessage
    form(method="POST" enctype="multipart/form-data")
        label(for="video") Video File
        input(type="file", accept="video/*",required, name="video", id="video")
        label(for="thumb") Thumbnail File
        input(type="file", accept="image/*",required, name="thumb", id="thumb")

        //.... 생략 ...

```

이럼 문제가 생기는데

route로 두 개의 파일을 보낸다는 거임

videoRouter에 있는 route 에는 영상만 업로드 할 준비가 되어 있고

썸네일을 업로드할 준비가 안됐음

이걸 이제 해결 할꺼임

## 14.6 Thumbnail Upload part Two

파일을 업로드 하려면 `Multer`를 사용해야함

```js
export const avatarUpload = multer({
  dest: "uploads/avatars/",
  limits: { fileSize: 3000000 },
});
export const videoUpload = multer({
  dest: "uploads/videos/",
  limits: { fileSize: 100000000 },
});
```

```js
videoRouter
  .route("/upload")
  .all(protectorMiddleware)
  .get(getUpload)
  .post(videoUpload.single("video"), postUpload);
```

videoUpload 미들웨어는 `upload.pug`의 form으로 부터 vdieo 파일을 받아옴

여기서 `single()` 이 아니라 `fields()` 를 쓰면 여러개를 받을 수 있음

```js
videoRouter
  .route("/upload")
  .all(protectorMiddleware)
  .get(getUpload)
  .post(
    videoUpload.fields([
      { name: "video", maxCount: 1 },
      { name: "thumb", maxCount: 2 },
    ]),
    postUpload
  );
```

이러면 postUpload controller 에 에러가 생길꺼임

왜냐면, postUpload controller는 req.file 을 기다리고 있거등

```js
export const postUpload = async (req, res) => {
  const {
    user: { _id },
  } = req.session;
  const { path: fileUrl } = req.file;
  // ....생략....
};
```

`fields()` 를 쓰면 req.file**s** 를 써야 하니까

```js
console.log(req.files);
```

해보면

```
[Object: null prototype] {
  video: [
    {
      fieldname: 'video',
      originalname: 'MyRecording.mp4',
      encoding: '7bit',
      mimetype: 'video/mp4',
      destination: 'uploads/videos/',
      filename: '0d74f3662026cdf341436ca27e6a2d18',
      path: 'uploads\\videos\\0d74f3662026cdf341436ca27e6a2d18',
      size: 56888
    }
  ],
  thumb: [
    {
      fieldname: 'thumb',
      originalname: 'MyThumbnail.jpg',
      encoding: '7bit',
      mimetype: 'image/jpeg',
      destination: 'uploads/videos/',
      filename: '6fe7443c00e50cbb583ef2ca86c810f2',
      path: 'uploads\\videos\\6fe7443c00e50cbb583ef2ca86c810f2',
      size: 8428
    }
  ]
}
```

이렇게 나옴

그러니까

```js
export const postUpload = async (req, res) => {
  const {
    user: { _id },
  } = req.session;

  const { video, thumb } = req.files;
  const { title, description, hashtags } = req.body;

  try {
    const newVideo = await Video.create({
      title,
      description,
      fileUrl: video[0].path,
      thumbUrl: thumb[0].path,
      owner: _id,
      hashtags: Video.formatHashtags(hashtags),
    });
  }
  //...생략....
```

이러면 된다~

`mixins/video.pug`

```pug
mixin video(video)
    a(href=`/videos/${video.id}`).video-mixin
        div.video-mixin__thumb(style=`background-image:url(${video.thumbUrl});background-size:cover;background-position:center;`)
```

그리고 썸세일에 해당되는 html 을 이렇게 바꿔주면

잘 안된다!~

이유는

섬네일 부분을 inspect 해보면

url의 path가 "uploads\videos\..." 이렇게 백슬래시로 되어있다는 거시다!

Linux 기반 운영체제들과는 달리 Windows의 path는 백슬래시를 사용한다는 것 같다는 거시다!

그렇기에

```js
thumbUrl: thumb[0].path.replace(/[\\]/g, "/"),
```

이렇게 하여 백슬을 교체 해주는 거시다!
